import streamlit as st
import requests
import json
import traceback
import csv
from datetime import datetime
import os
import sqlite3
import hashlib
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from dotenv import load_dotenv
import stripe
import io

# Optional: PostgreSQL support
try:
    import psycopg2
    from psycopg2.extras import execute_values
    HAS_POSTGRES = True
except ImportError:
    HAS_POSTGRES = False

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# Stripeã®è¨­å®š
stripe.api_key = os.getenv("STRIPE_SECRET_KEY")

# ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
DATA_DIR = "note_data"
if not os.path.exists(DATA_DIR):
    os.makedirs(DATA_DIR)

# æ—§DBã®ç§»è¡Œå‡¦ç† (ãƒ«ãƒ¼ãƒˆã«DBãŒã‚ã‚Šã€æ–°ãƒ•ã‚©ãƒ«ãƒ€ã«ãªã„å ´åˆ)
OLD_DB = "note_dashboard.db"
NEW_DB = os.path.join(DATA_DIR, "note_dashboard.db")
if os.path.exists(OLD_DB) and not os.path.exists(NEW_DB):
    try:
        import shutil
        shutil.move(OLD_DB, NEW_DB)
        # st.toastã‚’ä½¿ã†ã¨UIèµ·å‹•å‰ã«ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ãƒ­ã‚°ã®ã¿
        print(f"INFO: Moved {OLD_DB} to {NEW_DB}")
    except Exception as e:
        print(f"ERROR: Failed to move DB: {e}")

# =========================================================================
# 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ»åˆæœŸåŒ–
# =========================================================================
def get_db_info():
    db_url = os.getenv("DATABASE_URL")
    if db_url and HAS_POSTGRES: 
        return "postgres", db_url
    else: 
        return "sqlite", NEW_DB

def get_connection():
    db_type, db_target = get_db_info()
    if db_type == "postgres": return psycopg2.connect(db_target)
    else: return sqlite3.connect(db_target)

def init_db_schema():
    db_type, _ = get_db_info()
    try:
        conn = get_connection(); cursor = conn.cursor()
        if db_type == "postgres":
            cursor.execute('CREATE EXTENSION IF NOT EXISTS pgcrypto;')
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS app_users (
                    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
                    email TEXT UNIQUE NOT NULL,
                    password_hash TEXT NOT NULL,
                    is_approved BOOLEAN DEFAULT FALSE,
                    skip_stripe BOOLEAN DEFAULT FALSE,
                    created_at TIMESTAMPTZ DEFAULT NOW()
                );
            ''')
            cols = ["is_approved", "skip_stripe"]
            for col in cols:
                cursor.execute(f"DO $$ BEGIN IF NOT EXISTS (SELECT 1 FROM information_schema.columns WHERE table_name='app_users' AND column_name='{col}') THEN ALTER TABLE app_users ADD COLUMN {col} BOOLEAN DEFAULT FALSE; END IF; END $$")
            cursor.execute('CREATE TABLE IF NOT EXISTS article_stats (user_id TEXT, acquired_at TEXT, article_id BIGINT, title TEXT, views INTEGER, likes INTEGER, comments INTEGER, PRIMARY KEY (user_id, acquired_at, article_id));')
        else:
            cursor.execute('CREATE TABLE IF NOT EXISTS article_stats (user_id TEXT, acquired_at TEXT, article_id INTEGER, title TEXT, views INTEGER, likes INTEGER, comments INTEGER, PRIMARY KEY (user_id, acquired_at, article_id));')
        conn.commit(); conn.close()
    except Exception: pass

def check_stripe_subscription(email):
    if email == os.getenv("ADMIN_EMAIL"): return True
    if not stripe.api_key: return True
    try:
        customers = stripe.Customer.list(email=email, limit=1).data
        if not customers: return False
        customer_id = customers[0].id
        subs = stripe.Subscription.list(customer=customer_id, status='all', limit=5).data
        for sub in subs:
            if sub.status in ['active', 'trialling']: return True
        return False
    except Exception: return False

def neon_auth_login(email, password):
    db_type, _ = get_db_info()
    if db_type != "postgres": return True, "local"
    try:
        conn = get_connection(); cursor = conn.cursor()
        query = "SELECT email, is_approved, skip_stripe FROM app_users WHERE email = %s AND password_hash = crypt(%s, password_hash)"
        cursor.execute(query, (email, password))
        result = cursor.fetchone()
        if result:
            email_res, current_approved, skip_stripe = result
            access_allowed = True if skip_stripe else check_stripe_subscription(email)
            if access_allowed != current_approved:
                cursor.execute("UPDATE app_users SET is_approved = %s WHERE email = %s", (access_allowed, email))
                conn.commit()
            conn.close()
            if access_allowed: return True, "logged_in"
            else:
                p_link = os.getenv("STRIPE_PAYMENT_LINK", "#")
                return False, f"âš ï¸ ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ãŒæœ‰åŠ¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚[ã“ã¡ã‚‰ã®ãƒªãƒ³ã‚¯]({p_link}) ã‹ã‚‰æ±ºæ¸ˆã‚’å®Œäº†ã•ã›ã¦ãã ã•ã„ã€‚"
        else:
            conn.close(); return False, "ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã¾ãŸã¯ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚"
    except Exception as e: return False, f"èªè¨¼ã‚¨ãƒ©ãƒ¼: {str(e)}"

def neon_auth_signup(email, password):
    db_type, _ = get_db_info()
    if db_type != "postgres": return False, "Local mode doesn't support signup."
    try:
        conn = get_connection(); cursor = conn.cursor()
        cursor.execute("SELECT 1 FROM app_users WHERE email = %s", (email,))
        if cursor.fetchone():
            conn.close(); return False, "ã“ã®ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã¯æ—¢ã«ç™»éŒ²ã•ã‚Œã¦ã„ã¾ã™ã€‚"
        cursor.execute("INSERT INTO app_users (email, password_hash) VALUES (%s, crypt(%s, gen_salt('bf')))", (email, password))
        conn.commit(); conn.close()
        p_link = os.getenv("STRIPE_PAYMENT_LINK", "#")
        return True, f"âœ… ç™»éŒ²ãŒå®Œäº†ã—ã¾ã—ãŸï¼\n\n[ã“ã¡ã‚‰ã®Stripeæ±ºæ¸ˆãƒªãƒ³ã‚¯]({p_link}) ã‹ã‚‰æœˆé¡300å††ã®æ±ºæ¸ˆã‚’å®Œäº†ã•ã›ã¦ãã ã•ã„ã€‚\n\nã‚¯ãƒ¼ãƒãƒ³ `FREE30` ã§1ãƒ¶æœˆç„¡æ–™ã€`SPECIAL200` ã§ãšã£ã¨200å††ã«ãªã‚Šã¾ã™ã€‚æ±ºæ¸ˆå®Œäº†å¾Œã€ã™ãã«ãƒ­ã‚°ã‚¤ãƒ³å¯èƒ½ã§ã™ã€‚"
    except Exception as e: return False, f"ç™»éŒ²ã‚¨ãƒ©ãƒ¼: {str(e)}"

# --- ç®¡ç†æ©Ÿèƒ½ ---
def admin_get_all_users():
    try:
        conn = get_connection(); df = pd.read_sql("SELECT email, is_approved, skip_stripe, created_at FROM app_users ORDER BY created_at DESC", conn); conn.close()
        return df
    except Exception: return pd.DataFrame()

def admin_delete_user(email):
    try:
        uid = hashlib.sha256(email.encode()).hexdigest()[:16]
        conn = get_connection(); cursor = conn.cursor()
        cursor.execute("DELETE FROM article_stats WHERE user_id = %s", (uid,))
        cursor.execute("DELETE FROM app_users WHERE email = %s", (email,))
        conn.commit(); conn.close()
        return True
    except Exception: return False

def get_current_user_id(note_email):
    email = st.session_state.get("app_user_email", note_email)
    if not email: return "guest"
    return hashlib.sha256(email.encode()).hexdigest()[:16]

def get_default_credentials():
    email = ""; password = ""
    try:
        if "note" in st.secrets:
            email = st.secrets["note"].get("email", ""); password = st.secrets["note"].get("password", "")
    except: pass
    if not email: email = os.getenv("NOTE_EMAIL", "")
    if not password: password = os.getenv("NOTE_PASSWORD", "")
    return email, password

def note_auth(session, email, password):
    try:
        r = session.post('https://note.com/api/v1/sessions/sign_in', json={"login": email, "password": password})
        if "error" in r.json(): return None
        return session
    except Exception: return None

# =========================================================================
# 2. ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»è¡¨ç¤ºãƒ»ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# =========================================================================
def get_articles(session, user_id):
    articles = []; tdy = datetime.now().strftime('%Y-%m-%d'); page = 1
    pb = st.progress(0); txt = st.empty()
    while True:
        txt.text(f"ãƒšãƒ¼ã‚¸ {page} å–å¾—ä¸­...")
        try:
            r = session.get(f'https://note.com/api/v1/stats/pv?filter=all&page={page}&sort=pv')
            data = r.json(); stats = data.get('data', {}).get('note_stats', [])
            if not stats: break
            for item in stats:
                name = item.get('name')
                if name: articles.append((user_id, tdy, item.get('id'), name, item.get('read_count', 0), item.get('like_count', 0), item.get('comment_count', 0)))
            page += 1; pb.progress(min(page * 0.05, 1.0))
        except Exception: break
    pb.empty(); return articles

def save_data(data, save_dir=None):
    db_type, _ = get_db_info()
    try:
        conn = get_connection(); cursor = conn.cursor()
        if db_type == "postgres":
            q = "INSERT INTO article_stats (user_id, acquired_at, article_id, title, views, likes, comments) VALUES %s ON CONFLICT (user_id, acquired_at, article_id) DO NOTHING"
            execute_values(cursor, q, data)
        else: cursor.executemany('INSERT OR IGNORE INTO article_stats VALUES (?, ?, ?, ?, ?, ?, ?)', data)
        conn.commit(); conn.close()
        return True
    except Exception as e: 
        st.error(f"ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def import_excel_data(uploaded_files, user_id):
    added_dates = set()
    total_added = 0
    
    # æœ€æ–°ã®ã‚¿ã‚¤ãƒˆãƒ«->IDå¯¾å¿œè¡¨ã‚’ä½œæˆ
    db_type, _ = get_db_info()
    conn = get_connection(); cursor = conn.cursor()
    if db_type == "postgres":
        cursor.execute("SELECT title, article_id FROM article_stats WHERE user_id = %s ORDER BY acquired_at DESC", (user_id,))
    else:
        cursor.execute("SELECT title, article_id FROM article_stats WHERE user_id = ? ORDER BY acquired_at DESC", (user_id,))
    
    title_to_id = {}
    for t, aid in cursor.fetchall():
        if t not in title_to_id: title_to_id[t] = aid
    conn.close()

    for uploaded_file in uploaded_files:
        try:
            fname = uploaded_file.name.lower()
            if fname.endswith(".csv"):
                try:
                    df = pd.read_csv(uploaded_file, encoding="cp932")
                except:
                    uploaded_file.seek(0)
                    df = pd.read_csv(uploaded_file, encoding="utf-8")
            else:
                df = pd.read_excel(uploaded_file)
            
            col_map = {
                'æ—¥ä»˜': 'acquired_at', 'acquired_at': 'acquired_at', 'æ—¥æ™‚': 'acquired_at',
                'ã‚¿ã‚¤ãƒˆãƒ«': 'title', 'title': 'title', 'è¨˜äº‹å': 'title',
                'ãƒ“ãƒ¥ãƒ¼æ•°': 'views', 'views': 'views', 'PV': 'views', 'ãƒ“ãƒ¥ãƒ¼': 'views',
                'ã‚¹ã‚­æ•°': 'likes', 'likes': 'likes', 'ã‚¹ã‚­': 'likes',
                'ã‚³ãƒ¡ãƒ³ãƒˆæ•°': 'comments', 'comments': 'comments', 'ã‚³ãƒ¡ãƒ³ãƒˆ': 'comments'
            }
            df = df.rename(columns=lambda x: col_map.get(str(x).strip(), x))
            
            required_cols = ['acquired_at', 'title', 'views']
            if not all(col in df.columns for col in required_cols):
                st.error(f"ãƒ•ã‚¡ã‚¤ãƒ« {uploaded_file.name} ã«å¿…è¦ãªåˆ—ï¼ˆæ—¥ä»˜, ã‚¿ã‚¤ãƒˆãƒ«, ãƒ“ãƒ¥ãƒ¼æ•°ï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                continue
            
            data_to_save = []
            for _, row in df.iterrows():
                dt = pd.to_datetime(row['acquired_at']).strftime('%Y-%m-%d')
                title = str(row['title']).strip()
                article_id = title_to_id.get(title)
                if article_id is None:
                    article_id = -abs(int(hashlib.md5(title.encode()).hexdigest(), 16) % (10**10))
                
                data_to_save.append((
                    user_id, dt, article_id, title,
                    int(row.get('views', 0)),
                    int(row.get('likes', 0)),
                    int(row.get('comments', 0))
                ))
                added_dates.add(dt)
            
            conn = get_connection(); cursor = conn.cursor()
            if db_type == "postgres":
                cursor.execute("SELECT count(*) FROM article_stats WHERE user_id = %s", (user_id,))
                count_before = cursor.fetchone()[0]
                q = "INSERT INTO article_stats (user_id, acquired_at, article_id, title, views, likes, comments) VALUES %s ON CONFLICT (user_id, acquired_at, article_id) DO NOTHING"
                execute_values(cursor, q, data_to_save)
                cursor.execute("SELECT count(*) FROM article_stats WHERE user_id = %s", (user_id,))
                count_after = cursor.fetchone()[0]
            else:
                cursor.execute("SELECT count(*) FROM article_stats WHERE user_id = ?", (user_id,))
                count_before = cursor.fetchone()[0]
                cursor.executemany('INSERT OR IGNORE INTO article_stats VALUES (?, ?, ?, ?, ?, ?, ?)', data_to_save)
                cursor.execute("SELECT count(*) FROM article_stats WHERE user_id = ?", (user_id,))
                count_after = cursor.fetchone()[0]
            
            conn.commit(); conn.close()
            total_added += (count_after - count_before)
            
        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ« {uploaded_file.name} ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            
    return total_added, sorted(list(added_dates))



def get_sqlite_binary(user_id):


    """Postgresã¾ãŸã¯SQLiteã®ãƒ‡ãƒ¼ã‚¿ã‚’SQLiteãƒã‚¤ãƒŠãƒªã¨ã—ã¦å–å¾—ã™ã‚‹"""
    db_type, db_target = get_db_info()
    
    # ãƒ¡ãƒ¢ãƒªä¸Šã«ä¸€æ™‚çš„ãªSQLiteã‚’ä½œæˆ
    mem_conn = sqlite3.connect(':memory:')
    mem_cursor = mem_conn.cursor()
    mem_cursor.execute('CREATE TABLE article_stats (user_id TEXT, acquired_at TEXT, article_id INTEGER, title TEXT, views INTEGER, likes INTEGER, comments INTEGER, PRIMARY KEY (user_id, acquired_at, article_id));')
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    conn = get_connection(); cursor = conn.cursor()
    if db_type == "postgres":
        cursor.execute("SELECT * FROM article_stats WHERE user_id = %s", (user_id,))
    else:
        cursor.execute("SELECT * FROM article_stats WHERE user_id = ?", (user_id,))
    
    rows = cursor.fetchall()
    mem_cursor.executemany('INSERT INTO article_stats VALUES (?, ?, ?, ?, ?, ?, ?)', rows)
    mem_conn.commit()
    
    # ãƒã‚¤ãƒŠãƒªã«å¤‰æ›
    query = "".join(line for line in mem_conn.iterdump())
    
    # å®Ÿéš›ã«ã¯ iterdump ã§ã¯ãªãã€ãƒã‚¤ãƒŠãƒªã¨ã—ã¦ä¿å­˜ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿å‡ºã™å¿…è¦ãŒã‚ã‚‹
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
    temp_db_path = os.path.join(DATA_DIR, f"temp_dl_{user_id}.db")
    temp_conn = sqlite3.connect(temp_db_path)
    mem_conn.backup(temp_conn)
    temp_conn.close()
    mem_conn.close()
    conn.close()
    
    with open(temp_db_path, "rb") as f:
        data = f.read()
    
    os.remove(temp_db_path)
    return data

# =========================================================================
# 4. Streamlit UI
# =========================================================================
def main():
    init_db_schema(); db_type, _ = get_db_info()
    st.set_page_config(page_title="noteåˆ†æ v5", layout="wide")
    if "app_auth_token" not in st.session_state: st.session_state.app_auth_token = None
    if "app_user_email" not in st.session_state: st.session_state.app_user_email = None

    # --- ã‚¢ãƒ—ãƒªãƒ­ã‚°ã‚¤ãƒ³ ---
    if db_type == "postgres" and not st.session_state.app_auth_token:
        st.title("ğŸ›¡ï¸ noteåˆ†æã‚¢ãƒ—ãƒª ãƒ­ã‚°ã‚¤ãƒ³")
        tab_l, tab_s = st.tabs(["ãƒ­ã‚°ã‚¤ãƒ³", "æ–°è¦åˆ©ç”¨ç™»éŒ²"])
        
        with tab_l:
            with st.form("login"):
                e = st.text_input("ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹"); p = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password")
                if st.form_submit_button("ãƒ­ã‚°ã‚¤ãƒ³"):
                    ok, res = neon_auth_login(e, p)
                    if ok: st.session_state.app_auth_token=res; st.session_state.app_user_email=e; st.rerun()
                    else: st.error(res)
        
        with tab_s:
            st.write("âœ¨ **ãƒ—ãƒ¬ãƒŸã‚¢ãƒ  note åˆ†æãƒ„ãƒ¼ãƒ« (v5 Cloud)**")
            st.info("ã€ã”åˆ©ç”¨æ–™é‡‘ã€‘ æœˆé¡ 300 å††")
            with st.form("signup"):
                ne = st.text_input("ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹"); np = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password"); cp = st.text_input("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰(ç¢ºèª)", type="password")
                if st.form_submit_button("ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½œæˆã—ã¦æ±ºæ¸ˆã¸é€²ã‚€"):
                    if np != cp: st.error("ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ä¸ä¸€è‡´")
                    elif len(np)<4: st.error("4æ–‡å­—ä»¥ä¸Šå¿…è¦")
                    else: ok, msg = neon_auth_signup(ne, np); st.info(msg) if ok else st.error(msg)
        return

    is_admin = (st.session_state.app_user_email == os.getenv("ADMIN_EMAIL")) if os.getenv("ADMIN_EMAIL") else False
    st.sidebar.header("ğŸ”‘ è¨­å®š")
    if st.session_state.app_user_email:
        st.sidebar.info(f"ğŸ‘¤ {st.session_state.app_user_email}")
        if st.sidebar.button("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ"):
            st.session_state.app_auth_token=None
            st.session_state.app_user_email=None
            st.rerun()

    menu = ["ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰", "ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ç®¡ç†"]; 
    if is_admin: menu.append("ğŸ› ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç†")
    choice = st.sidebar.radio("ãƒ¡ãƒ‹ãƒ¥ãƒ¼", menu)

    # å…±é€šãƒ‡ãƒ¼ã‚¿å–å¾—
    de, dp = get_default_credentials()
    ne = st.sidebar.text_input("noteãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹", value=de)
    np = st.sidebar.text_input("noteãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰", type="password", value=dp)
    uid = get_current_user_id(ne)

    if choice == "ğŸ› ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼ç®¡ç†":
        st.title("ğŸ› ï¸ ç®¡ç†è€…ç”»é¢")
        df = admin_get_all_users()
        if not df.empty:
            df['status'] = df['is_approved'].apply(lambda x: "âœ… è¨±å¯æ¸ˆ" if x else "â³ æœªæ±ºæ¸ˆ/åœæ­¢ä¸­")
            st.dataframe(df[['email', 'status', 'created_at']], use_container_width=True)
            with st.expander("ğŸ—‘ï¸ ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®å‰Šé™¤"):
                te = st.text_input("å‰Šé™¤ã™ã‚‹ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹")
                if st.button("å®Œå…¨ã«å‰Šé™¤ã™ã‚‹"):
                    if admin_delete_user(te): st.success(f"{te} ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚"); st.rerun()
        return

    if choice == "ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ç®¡ç†":
        st.title("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ç®¡ç† (CSVã‚¤ãƒ³ãƒãƒ¼ãƒˆ & åŒæœŸ)")
        
        # ãƒ‡ãƒ¼ã‚¿å–å¾—çŠ¶æ³ã®å¯è¦–åŒ–
        try:
            conn = get_connection()
            q = "SELECT DISTINCT acquired_at FROM article_stats WHERE user_id = %s" if db_type == "postgres" else "SELECT DISTINCT acquired_at FROM article_stats WHERE user_id = ?"
            df_dates = pd.read_sql(q, conn, params=(uid,))
            conn.close()
            
            if not df_dates.empty:
                st.subheader("ğŸ“… ãƒ‡ãƒ¼ã‚¿å–å¾—çŠ¶æ³ (ç›´è¿‘6ãƒ¶æœˆ)")
                df_dates['acquired_at'] = pd.to_datetime(df_dates['acquired_at'], format='mixed')
                acquisition_dates = df_dates['acquired_at'].dt.date.unique()
                
                end_date = datetime.now().date()
                start_date = end_date - pd.DateOffset(months=5)
                start_date = start_date.replace(day=1).date()
                
                all_days = pd.date_range(start_date, end_date)
                status_df = pd.DataFrame({'date': all_days.date})
                status_df['status'] = status_df['date'].apply(lambda x: 1 if x in acquisition_dates else 0)
                status_df['month'] = pd.to_datetime(status_df['date']).dt.strftime('%Y-%m')
                status_df['day'] = pd.to_datetime(status_df['date']).dt.day
                
                pivot_status = status_df.pivot(index='month', columns='day', values='status').fillna(-1)
                
                colors = [[0.0, "#ffffff"], [0.4, "#ffffff"], [0.5, "#f0f0f0"], [0.6, "#f0f0f0"], [1.0, "#2ea44f"]]
                fig_heat = px.imshow(
                    pivot_status,
                    labels=dict(x="æ—¥", y="æœˆ", color="å–å¾—çŠ¶æ³"),
                    x=pivot_status.columns,
                    y=pivot_status.index,
                    color_continuous_scale=colors,
                    zmin=-1, zmax=1, height=280
                )
                fig_heat.update_coloraxes(showscale=False)
                fig_heat.update_layout(xaxis=dict(dtick=1, side="top"), yaxis=dict(autorange="reversed"), margin=dict(l=10, r=10, t=30, b=10))
                st.plotly_chart(fig_heat, use_container_width=True)
                st.caption("ğŸŸ¢: ãƒ‡ãƒ¼ã‚¿ã‚ã‚Š / âšª: ãƒ‡ãƒ¼ã‚¿ãªã—")
            else:
                st.info("ãƒ‡ãƒ¼ã‚¿ãŒã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ã‹ã€CSVã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚")
        except Exception as e:
            st.error(f"å–å¾—çŠ¶æ³ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

        st.markdown("---")
        st.subheader("1. éå»ãƒ‡ãƒ¼ã‚¿ã®å–ã‚Šè¾¼ã¿")
        st.info("CSVã¾ãŸã¯Excelãƒ•ã‚¡ã‚¤ãƒ« (.csv / .xlsx / .xlsm) ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚åˆ—åã«ã€Œæ—¥ä»˜ã€ã€Œã‚¿ã‚¤ãƒˆãƒ«ã€ã€Œãƒ“ãƒ¥ãƒ¼æ•°ã€ãŒå«ã¾ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®æä¾› (Excelã§æ–‡å­—åŒ–ã‘ã—ãªã„ã‚ˆã†Shift-JISã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰)
        sample_text = "æ—¥ä»˜,ã‚¿ã‚¤ãƒˆãƒ«,ãƒ“ãƒ¥ãƒ¼æ•°,ã‚¹ã‚­æ•°,ã‚³ãƒ¡ãƒ³ãƒˆæ•°\n2023-12-01,ã‚µãƒ³ãƒ—ãƒ«è¨˜äº‹A,150,15,2\n2023-12-01,ã‚µãƒ³ãƒ—ãƒ«è¨˜äº‹B,80,8,0"
        sample_bytes = sample_text.encode("cp932")
        st.download_button(label="ğŸ“„ ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«(CSV)ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=sample_bytes, file_name="note_import_sample.csv", mime="text/csv")
        st.caption("â€» ã‚µãƒ³ãƒ—ãƒ«ã«ã¯ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒå…¥ã£ã¦ã„ã¾ã™ã€‚ã”è‡ªèº«ã®ãƒ‡ãƒ¼ã‚¿ã«æ›¸ãæ›ãˆã¦ï¼ˆã¾ãŸã¯è¡Œã‚’å‰Šé™¤ã—ã¦ï¼‰ã‹ã‚‰ä¿å­˜ãƒ»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        
        files = st.file_uploader("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ (è¤‡æ•°å¯)", type=["csv", "xlsx", "xlsm"], accept_multiple_files=True)
        if st.button("ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ"):
            if files:
                added_count, dates = import_excel_data(files, uid)
                st.success(f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†: {added_count} ä»¶ã®æ–°ã—ã„ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚")
                if dates:
                    with st.expander("å¯¾è±¡ã¨ãªã£ãŸæ—¥ä»˜ä¸€è¦§"):
                        st.write(", ".join(dates))
                st.rerun()
            else:
                st.warning("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
        
        st.markdown("---")
        st.subheader("2. ãƒ‡ãƒ¼ã‚¿ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (åŒæœŸç”¨)")
        st.write("ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…å®¹ã‚’SQLiteå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã¨ã®åŒæœŸã«ã”æ´»ç”¨ãã ã•ã„ã€‚")
        
        try:
            db_bin = get_sqlite_binary(uid)
            suffix = "cloud" if db_type == "postgres" else "local"
            fn = f"note_dashboard_{suffix}_{datetime.now().strftime('%Y%m%d')}.db"
            st.download_button(label="ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (.db)", data=db_bin, file_name=fn, mime="application/octet-stream")
        except Exception as e:
            st.error(f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æº–å‚™ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        
        return

    # --- ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ ---
    st.title("ğŸ“ noteåˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")
    
    if st.sidebar.button("æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹"):
        s = requests.session()
        if note_auth(s, ne, np):
            data = get_articles(s, uid)
            if data: 
                if save_data(data): st.success("ä¿å­˜å®Œäº†ï¼"); st.rerun()
        else: st.sidebar.error("noteã®èªè¨¼ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    st.sidebar.caption("â€» 1æ—¥1å›ã®å®Ÿè¡Œã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    try:
        conn = get_connection()
        q = "SELECT * FROM article_stats WHERE user_id = %s" if db_type == "postgres" else "SELECT * FROM article_stats WHERE user_id = ?"
        df_all = pd.read_sql(q, conn, params=(uid,))
        conn.close()
    except Exception:
        df_all = pd.DataFrame()

    if not df_all.empty:
        df_all['acquired_at'] = pd.to_datetime(df_all['acquired_at'], format='mixed')
        df_all = df_all.sort_values('acquired_at')
        
        # --- ã‚µãƒãƒªãƒ¼ ---
        ud = sorted(df_all['acquired_at'].unique())
        latest = ud[-1]
        df_latest = df_all[df_all['acquired_at'] == latest].sort_values('views', ascending=False)
        
        has_prev = len(ud) >= 2
        vd = 0
        if has_prev:
            df_p = df_all[df_all['acquired_at'] == ud[-2]]
            df_m = pd.merge(df_latest[['article_id', 'views']], df_p[['article_id', 'views']], on='article_id', suffixes=('', '_prev'), how='left').fillna(0)
            vd = int((df_m['views'] - df_m['views_prev']).sum())

        st.info(f"æœ€çµ‚æ›´æ–°: {latest.strftime('%Y-%m-%d')}")
        c1, c2, c3 = st.columns(3)
        c1.metric("å…¬é–‹è¨˜äº‹æ•°", f"{len(df_latest)} è¨˜äº‹")
        c2.metric("ç´¯è¨ˆãƒ“ãƒ¥ãƒ¼", f"{df_latest['views'].sum():,}", delta=f"+{vd:,}" if has_prev else None)
        c3.metric("ç´¯è¨ˆã‚¹ã‚­", f"{df_latest['likes'].sum():,}")
        
        st.markdown("---")
        
        # --- ãƒ¡ã‚¤ãƒ³ã‚°ãƒ©ãƒ• ---
        if has_prev:
            st.subheader("ğŸ“ˆ å…¨ä½“ç´¯è¨ˆãƒ“ãƒ¥ãƒ¼æ¨ç§»")
            tv = df_all.groupby('acquired_at')['views'].sum().reset_index()
            fig = px.line(tv, x='acquired_at', y='views')
            fig.update_layout(xaxis_type='date', yaxis=dict(tickformat=',d', rangemode='tozero'))
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("ğŸ“‰ æ¨ç§»ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã™ã‚‹ã«ã¯ã€2æ—¥åˆ†ä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™ã€‚")

        t1, t2, t3 = st.tabs(["ğŸ“Š ç´¯è¨ˆãƒ©ãƒ³ã‚­ãƒ³ã‚°", "ğŸ”¥ æœ¬æ—¥ã®ä¼¸ã³", "ğŸ“ˆ ç”Ÿãƒ‡ãƒ¼ã‚¿"])
        with t1:
            fig = px.bar(df_latest.head(20), x='views', y='title', orientation='h', text_auto=True)
            fig.update_layout(yaxis={'autorange': 'reversed'}, height=600)
            st.plotly_chart(fig, use_container_width=True)
        with t2:
            if has_prev:
                df_p = df_all[df_all['acquired_at'] == ud[-2]]
                df_m = pd.merge(df_latest[['article_id', 'title', 'views']], df_p[['article_id', 'views']], on='article_id', suffixes=('', '_prev'), how='left').fillna(0)
                df_m['views_delta'] = df_m['views'] - df_m['views_prev']
                df_d = df_m.sort_values('views_delta', ascending=False)
                fig = px.bar(df_d.head(20), x='views_delta', y='title', orientation='h', text_auto=True)
                fig.update_layout(yaxis={'autorange': 'reversed'}, height=600)
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.info("æ¯”è¼ƒå¯¾è±¡ã®éå»ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        with t3:
            st.dataframe(df_latest, use_container_width=True)
            
        st.markdown("---")
        if has_prev:
            st.subheader("ğŸ“Š å€‹åˆ¥ãƒ“ãƒ¥ãƒ¼æ•°æ¨ç§»")
            ps = df_all[['acquired_at', 'title', 'views']].drop_duplicates(['acquired_at', 'title'])
            pdf = ps.pivot(index='acquired_at', columns='title', values='views')
            fig = go.Figure()
            for t in pdf.columns:
                fig.add_trace(go.Scatter(x=pdf.index, y=pdf[t], mode='lines+markers', name=t, connectgaps=True))
            
            fig.update_layout(
                hovermode='closest', # ãƒã‚¦ã‚¹ã«ä¸€ç•ªè¿‘ã„è¨˜äº‹ã ã‘ã‚’è¡¨ç¤º
                showlegend=False,    # å‡¡ä¾‹ã¯éè¡¨ç¤º
                height=700, 
                xaxis_type='date', 
                yaxis=dict(tickformat=',d'),
                margin=dict(l=10, r=10, t=10, b=10)
            )
            # ãƒ›ãƒãƒ¼ãƒ©ãƒ™ãƒ«ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å…¨æ–‡è¡¨ç¤ºã™ã‚‹è¨­å®š
            fig.update_traces(
                hoverlabel=dict(namelength=-1, font_size=12), # ã‚¿ã‚¤ãƒˆãƒ«å…¨æ–‡è¡¨ç¤º
                mode='lines' # ãƒãƒ¼ã‚«ãƒ¼ã¯æ¶ˆã—ã¦ã‚¹ãƒƒã‚­ãƒªã•ã›ã‚‹
            ) 
            
            st.plotly_chart(fig, use_container_width=True)
            
    else:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã€Œæœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã‹ã€CSVã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¦ãã ã•ã„ã€‚")

if __name__ == "__main__":
    main()
